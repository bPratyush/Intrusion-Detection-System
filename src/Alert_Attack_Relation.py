class PoissonDistribution:
  """Poisson distribution with fixed mean."""
  def __init__(self, lam=100):
    """
    Construct a Poisson distribution object.
    :param lam: Mean of the distribution.
    """
    self.mean = lam
    self.generate = lambda: poisson(lam)


class AlertType:
  """Representation of an alert type."""
  #False Alerts are generated using Poisson Distribution
  def __init__(self, cost=1, false_alerts=PoissonDistribution(), name=None):
    """
    Construct an alert type object.
    :param cost: Cost of investigating an alert of this type (i.e., C_t).
    :param false_alerts: Distribution of false alerts of this type (i.e., F_t).
    :param name: Name of this alert type.
    """
    assert(cost > 0)
    self.cost = cost
    self.false_alerts = false_alerts
    self.name = name
  
class AttackType:
  """Representation of an attack type."""
  def __init__(self, loss, cost, pr_alert, name):
    """
    Construct an attack type object.
    :param loss: Loss inflicted by an undetected attack of this type for various ages (i.e., L_{h,a}). Single-dimensional list of floats, length equal to the time horizon.
    :param cost: Cost of mounting an attack of this type (i.e., E_a).
    :param pr_alert: Probability of triggering an alert for various alert types (i.e., P_{a,t}). Single-dimensional list of floats, length equal to the number of alert types.
    :param name: Name of this attack type.
    """
    assert(cost > 0)
    assert(min(loss) >= 0)
    #assert(min(pr_alert) >= 0.0)
    #assert(max(pr_alert) <= 1.0)
    self.loss = loss
    self.cost = cost
    self.pr_alert = pr_alert
    self.name = name

def next_state(self, mode, state, delta, alpha, rnd=None):
    """
    Compute the next state of the game given a defense action and an adversarial strategy. Note that the defense action delta is the specific number of alerts delta to investigate, while the adversary strategy alpha is a policy that returns the attack action given the state of the game.
    :param state: State of the alert prioritization problem (i.e., Model.State object).
    :param delta: Number of alerts to investigate. Two-dimensional list, delta[h][t] is the number of alerts to investigate of type t raised h time steps ago.
    :param alpha: Attack policy. Function, takes a model and a state, returns the probability of mounting attacks (one-dimensional list) given a model and a state.
    :param rnd: Random number generator.
    :return: Next state (i.e., Model.State object).
    """
    if isinstance(delta, list):
      delta = copy.deepcopy(delta)
    else:
      delta = delta(self, state)
    delta = self.make_investigation_feasible(state.N, delta)

    assert(self.is_feasible_investigation(state.N, delta))
    if rnd is None:
      rnd = self.rnd
    next = Model.State(self)

    #print("state.M before investigation:", state.M)
    # 1. Attack investigation
    M_now = copy.deepcopy(state.M)
    for a in range(len(self.attack_types)):
      for h in range(self.horizon):
        coin = np.random.random()
        fact = product([1 - np.sign(state.R[h][a][t]) * prob_investigation(state.N[h][t], self.attack_types[a].pr_alert[t], delta[h][t], state.R[h][a][t])  for t in range(len(self.alert_types))])
        #fact = product([scipy.special.comb(state.N[h][t]-state.R[h][a][t], delta[h][t], exact=True) / scipy.special.comb(state.N[h][t], delta[h][t], exact=True) for t in range(len(self.alert_types))])
        #print("attack: {} coin: {} fact :{}".format(a, coin, fact))
        if (state.M[h][a] == 1) and (coin < fact):
          state.M[h][a] = 1
        else:
          state.M[h][a] = 0
    #print("state.M after investigation", state.M) 

    def_loss = 0.0
    if mode == 'new':
      for a in range(len(self.attack_types)):
        if M_now[0][a] == 1 and state.M[0][a] == 1:
          def_loss += self.attack_types[a].loss[0]
        if M_now[0][a] == 1 and state.M[0][a] == 0:
          def_loss -= self.attack_types[a].loss[0]
    else:
      for a in range(len(self.attack_types)):
        def_loss += self.attack_types[a].loss[0] * state.M[0][a]
    
    # 2. Attacks
    if isinstance(alpha, list):
      pr_attacks = copy.deepcopy(alpha)
    else:
      pr_attacks = alpha(self, state)
    pr_attacks = self.make_attack_feasible(pr_attacks)
    if not self.is_feasible_attack(pr_attacks):
      print(pr_attacks)
    assert(self.is_feasible_attack(pr_attacks))
    for a in range(len(self.attack_types)):
      if np.random.random() < pr_attacks[a]:
        next.M[0][a] = 1
      else:
        next.M[0][a] = 0

    #print(pr_attacks, delta)
    next.U = state.U + def_loss

    # 3. True alerts
#Loop over Attack Types
    for a in range(len(self.attack_types)):
    #Loop Over Alert Types
      for t in range(len(self.alert_types)):
#R[0][a][t]: Count of true alerts of type t specifically generated by an attack of type a at time step 0
#M[0][a]: Binary value indicating the presence (1) or absence (0) of an attack of type a at time step 0
#self.attack_types[a].pr_alert[t] : Probability of Generating Alert of type t given presence of Adversial Attack a
        #Randomness in Alert and Attack Relationship
        if np.random.random() < self.attack_types[a].pr_alert[t] * next.M[0][a]:
          ##Randomness to count number of alerts is related to the stochastic nature of alert generation.
          #If random number less than the product, Alert generated of type t
          next.R[0][a][t] = math.ceil(self.attack_types[a].pr_alert[t])
        else:
          #Else Alert of that type not generated
          next.R[0][a][t] = 0

    # 4. Alerts
#Loop over Alert Types
    for t in range(len(self.alert_types)):
#self.alert_types[t].false_alerts.generate() generates the number of false alerts for the current alert type.
#sum((next.R[0][a][t] for a in range(len(self.attack_types)))) calculates the sum of true alerts for the current alert type t across all attack types.
# N[0][t] = Total number of alerts (both false and true) triggered by attacks to be investiagted 
      next.N[0][t] = self.alert_types[t].false_alerts.generate() + sum((next.R[0][a][t] for a in range(len(self.attack_types))))
    return next


#TEST.py
def test_model_fraud(def_budget, adv_budget):
  """
  Creat a test model by using the credit fraud dataset (H = 1, |T| = 6, |A| = 6).
  :return: Model object. 
  """
  #pr_alert (Probability of Generating an Alert) : User-specified and defined when creating instances of the AttackType class.
  alert_types =  [AlertType(1.0, PoissonDistribution(10), "t1"), 
                  AlertType(1.0, PoissonDistribution(47), "t4"),
                  AlertType(1.0, PoissonDistribution(39), "t6")]
  attack_types = [AttackType([9.374], 1, [1.0*0.9, 0.67*0.9, 0.0], "a1"),
                  AttackType([12.14], 3, [0.01*0.9, 0.96*0.9, 0.13*0.9], "a4"),
                  AttackType([16.03], 2, [0.0, 0.45*0.9, 0.94*0.9], "a6")]
  model = Model(1, alert_types, attack_types, def_budget, adv_budget)
  return model
